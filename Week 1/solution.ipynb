{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a possible solution for the Week 1 labo made in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given is a dataset of Iris flowers. Each flower is described by 4 features: sepal length, sepal width, petal length, and petal width. The goal is to classify the flowers into one of three species: Iris setosa, Iris versicolor, or Iris virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Labels:  ['setosa' 'versicolor' 'virginica']\n",
      "Data shape:  (150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "# print the names of the 4 features\n",
    "print(\"Features: \", iris.feature_names)\n",
    "\n",
    "# print the label type of iris\n",
    "print(\"Labels: \", iris.target_names)\n",
    "\n",
    "# print data(feature)shape\n",
    "print(\"Data shape: \", iris.data.shape)\n",
    "\n",
    "# print the iris data features (top 5 records)\n",
    "print(iris.data[0:5])\n",
    "\n",
    "# print the iris labels (0:setosa, 1:versicolor, 2:virginica)\n",
    "print(iris.target)\n",
    "\n",
    "# print the length of the iris dataset\n",
    "print(len(iris.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=seed)  # 70% training\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = t.relu(self.fc1(x))\n",
    "        x = t.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choising the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(NeuralNetwork().parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 1.0817012786865234\n",
      "Epoch 100 - Loss: 1.1121052503585815\n",
      "Epoch 200 - Loss: 1.1202964782714844\n",
      "Epoch 300 - Loss: 1.0727903842926025\n",
      "Epoch 400 - Loss: 1.2573022842407227\n",
      "Epoch 500 - Loss: 1.2051637172698975\n",
      "Epoch 600 - Loss: 1.137162685394287\n",
      "Epoch 700 - Loss: 1.0995595455169678\n",
      "Epoch 800 - Loss: 1.5541194677352905\n",
      "Epoch 900 - Loss: 1.098450779914856\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "amount_of_epochs = 1000\n",
    "\n",
    "for epoch in range(amount_of_epochs):\n",
    "    optimizer.zero_grad() # clear the gradients\n",
    "    outputs = NeuralNetwork()(t.tensor(X_train).float()) # forward pass, makes sure the input is a float tensor\n",
    "    loss = loss_function(outputs, t.tensor(y_train)) # calculate the loss\n",
    "    loss.backward() # backward pass\n",
    "    optimizer.step() # update weights\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch} - Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.422\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "\n",
    "with t.no_grad(): #\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    outputs = NeuralNetwork()(t.tensor(X_test).float())\n",
    "    for idx, i in enumerate(outputs):\n",
    "        if t.argmax(i) == t.tensor(y_test[idx]):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    print('Accuracy: ', round(correct / total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the accuracy of our modl is only 0.311. This is because we have a very small dataset and we are not using any advanced techniques to improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While working on a project, you might want to save your model so that you can use it later. You can save the model using the `torch.save` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "t.save(NeuralNetwork().state_dict(), 'iris_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model and making predictions is very easy. You can load the model using the `torch.load` function and then use the model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6598/3603961524.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(t.load('iris_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(t.load('iris_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3971, -0.5863,  0.5146]], grad_fn=<AddmmBackward0>)\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "random_iris = t.tensor([[5.1, 3.5, 1.4, 0.2]]) # setosa\n",
    "\n",
    "prediction = model(random_iris.float())\n",
    "print(prediction)\n",
    "print(t.argmax(prediction))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
