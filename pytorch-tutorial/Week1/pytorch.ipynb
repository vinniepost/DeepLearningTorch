{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplearning with cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info about the codeblock bellow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is able to run on GPU, but this is not enabled by default. We check if the GPU is available and enable it if it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed\n",
    "random_seed = 42\n",
    "\n",
    "# Import the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explenation of the codeblock bellow\n",
    "torch.FloatTensor converts input to a float tensor (a tensor can only contain one type of data [documentation](https://pytorch.org/docs/stable/tensors.html) ) \\\n",
    "Float: 32-bit floating point \\\n",
    "Long: 64-bit integer (signed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to PyTorch tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch models are created by subclassing `torch.nn.Module`. The model is defined by the `__init__` method, where the layers are defined, and the `forward` method, where the forward pass is defined. \\\n",
    "In the `__init__` method we define the layers of the model. \\\n",
    "__fc__ stands for fully connected layer. \\\n",
    "The layers available in PyTorch are defined in the `torch.nn` module. [Documentation](https://pytorch.org/docs/stable/nn.html) \\\n",
    "Since we want a fully connected layer, we use the [torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) class. \\\n",
    "The forward method defines the forward pass of the model. \\\n",
    "In the forward method we define the operations that are performed on the input data. \\\n",
    "We use the [torch.nn.functional](https://pytorch.org/docs/stable/nn.functional.html) module to define the operations. \\\n",
    "The activation functions are defined in the `torch.nn.functional` module. \\\n",
    "We use the [torch.nn.functional.relu](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.relu) function to apply the ReLU activation function. \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # Call the parent class's constructor\n",
    "        self.fc1 = nn.Linear(4, 100) # 4 input features, 100 output features\n",
    "        self.fc2 = nn.Linear(100, 100) # 100 input features, 100 output features\n",
    "        self.fc3 = nn.Linear(100, 3) # 100 input features, 3 output features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5) # Added to show different loss in tensorboard\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the neural network\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = net(X_train)\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test the neural network\n",
    "y_pred = net(X_test)\n",
    "_, predicted = torch.max(y_pred, 1)\n",
    "\n",
    "print(accuracy_score(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "# # Save the model\n",
    "# torch.save(net.state_dict(), 'model.pth')\n",
    "\n",
    "# # Load the model\n",
    "# net = Net()\n",
    "# net.load_state_dict(torch.load('model.pth'))\n",
    "# net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a writer for tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 1.11858069896698\n",
      "Epoch: 10 Loss: 1.124367356300354\n",
      "Epoch: 20 Loss: 1.1071430444717407\n",
      "Epoch: 30 Loss: 1.1568927764892578\n",
      "Epoch: 40 Loss: 1.1178781986236572\n",
      "Epoch: 50 Loss: 1.077290415763855\n",
      "Epoch: 60 Loss: 1.0895156860351562\n",
      "Epoch: 70 Loss: 1.1391804218292236\n",
      "Epoch: 80 Loss: 1.0739704370498657\n",
      "Epoch: 90 Loss: 1.1220403909683228\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='runs/iris_experiment_1', comment='Iris dataset training')\n",
    "\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def train_model(iter):\n",
    "    for epoch in range(iter):\n",
    "        optimizer.zero_grad()\n",
    "        y1 = model(X_train)\n",
    "        loss = criterion(y1, y_train)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        writer.add_histogram(\"fc1.weight\", model.fc1.weight, epoch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch:', epoch, 'Loss:', loss.item())\n",
    "\n",
    "train_model(100)\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard is a tool that allows you to visualize the training process of your model. \\\n",
    "we can run it via the command `tensorboard --logdir=runs` where runs is the folder where runs are stored \\\n",
    "installing this is done via `pip install tensorboard` \\\n",
    "It might be worth looking into the tensorboard integration in pytorch with vs code. [here](https://code.visualstudio.com/docs/python/tensorboard) \\\n",
    "open this via command palette (ctrl+shift+p) and search for Python: Launch Tensorboard \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## herschrijving van de code die u had gegeven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 1: Zet je kaggle api in /root/.config/kaggle.json \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'categoryCrossEntropyLoss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(test_labels)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Create a neural network\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNet\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28msuper\u001b[39m(Net, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m() \u001b[38;5;66;03m# Call the parent class's constructor\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[41], line 53\u001b[0m, in \u001b[0;36mNet\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     52\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> 53\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mcategoryCrossEntropyLoss()\n\u001b[1;32m     54\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'categoryCrossEntropyLoss'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# load the minst fashion dataset from kaggle\n",
    "if not os.path.exists('fashionmnist/fashion-mnist_test.csv'):\n",
    "    !rm -rf fashionmnist\n",
    "    !kaggle datasets download -d zalando-research/fashionmnist\n",
    "    !mkdir fashionmnist\n",
    "    !unzip fashionmnist.zip -d fashionmnist \n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('fashionmnist/fashion-mnist_train.csv')\n",
    "test_data = pd.read_csv('fashionmnist/fashion-mnist_test.csv')\n",
    "\n",
    "train_images = train_data.iloc[:, 1:].values\n",
    "train_labels = train_data.iloc[:, 0].values\n",
    "\n",
    "test_images = test_data.iloc[:, 1:].values\n",
    "test_labels = test_data.iloc[:, 0].values\n",
    "\n",
    "# Convert the dataset to PyTorch tensors\n",
    "# numpy.ndarray to torch.tensor that contains float values\n",
    "\n",
    "train_images = torch.FloatTensor(train_images)\n",
    "train_labels = torch.LongTensor(train_labels)\n",
    "test_images = torch.FloatTensor(test_images)\n",
    "test_labels = torch.LongTensor(test_labels)\n",
    "\n",
    "\n",
    "# Create a neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # Call the parent class's constructor\n",
    "        self.fc1 = nn.Linear(28*28, 128) # 784 input features, 128 output features\n",
    "        self.fc2 = nn.Linear(128, 128) # 128 input features, 128 output features\n",
    "        self.fc3 = nn.Linear(128, 10) # 128 input features, 10 output features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "net = Net()\n",
    "\n",
    "for epoch in range(10):\n",
    "    net.optimizer.zero_grad()\n",
    "    output = net(train_images)\n",
    "    net.loss = criterion(output, train_labels)\n",
    "    net.loss.backward()\n",
    "    net.optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch:', epoch, 'Loss:', net.loss.item())\n",
    "    \n",
    "y_pred = net(test_images)\n",
    "_, predicted = torch.max(y_pred, 1)\n",
    "\n",
    "print(accuracy_score(test_labels, predicted))\n",
    "print(confusion_matrix(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code met tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_755/3457683471.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc2(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 2.3036961555480957\n",
      "Epoch: 10 Loss: 2.3036999702453613\n",
      "0.1\n",
      "[[   0    0    0    0    0    0 1000    0    0    0]\n",
      " [   0    0    0    0    0    0 1000    0    0    0]\n",
      " [   0    0    0    0    0    0 1000    0    0    0]\n",
      " [   0    0    0    0    0    0 1000    0    0    0]\n",
      " [   0    0    0    0    0    0 1000    0    0    0]\n",
      " [   0    0    0    0    0    0 1000    0    0    0]\n",
      " [   0    0    0    0    0    0 1000    0    0    0]\n",
      " [   0    0    0    0    0    0 1000    0    0    0]\n",
      " [   0    0    0    0    0    0 1000    0    0    0]\n",
      " [   0    0    0    0    0    0 1000    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='runs/hassan', comment='Code provided by Hassan H.')\n",
    "\n",
    "# # load the minst fashion dataset from kaggle\n",
    "# if not os.path.exists('fashionmnist/fashion-mnist_test.csv'):\n",
    "#     !rm -rf fashionmnist\n",
    "#     !kaggle datasets download -d zalando-research/fashionmnist\n",
    "#     !mkdir fashionmnist\n",
    "#     !unzip fashionmnist.zip -d fashionmnist \n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('fashionmnist/fashion-mnist_train.csv')\n",
    "test_data = pd.read_csv('fashionmnist/fashion-mnist_test.csv')\n",
    "\n",
    "train_images = (train_data.drop('label', axis=1) / 255.0)\n",
    "train_labels = train_data['label']\n",
    "\n",
    "test_images = (test_data.drop('label', axis=1) / 255.0)\n",
    "test_labels = test_data['label']\n",
    "\n",
    "# train_images = train_data.iloc[:, 1:].values / 255.0\n",
    "# train_labels = train_data.iloc[:, 0].values\n",
    "\n",
    "# test_images = test_data.iloc[:, 1:].values / 255.0\n",
    "# test_labels = test_data.iloc[:, 0].values\n",
    "\n",
    "# Convert the dataframe to PyTorch tensors\n",
    "# numpy.ndarray to torch.tensor that contains float values\n",
    "\n",
    "train_images = torch.FloatTensor(train_images.values)\n",
    "train_labels = torch.LongTensor(train_labels.values)\n",
    "test_images = torch.FloatTensor(test_images.values)\n",
    "test_labels = torch.LongTensor(test_labels.values)\n",
    "\n",
    "\n",
    "# Create a neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # Call the parent class's constructor\n",
    "        self.fc1 = nn.Linear(28*28, 128) # 784 input features, 128 output features\n",
    "        self.fc2 = nn.Linear(128, 128) # 128 input features, 128 output features\n",
    "        self.fc3 = nn.Linear(128, 10) # 128 input features, 10 output features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "net = Net()\n",
    "\n",
    "for epoch in range(20):\n",
    "    net.optimizer.zero_grad()\n",
    "    output = net(train_images)\n",
    "    net.loss = criterion(output, train_labels)\n",
    "    net.loss.backward()\n",
    "    writer.add_scalar(\"Loss/train\", net.loss, epoch)\n",
    "    writer.add_histogram(\"fc1.weight\", net.fc1.weight, epoch)\n",
    "    writer.add_histogram(\"fc2.weight\", net.fc2.weight, epoch)\n",
    "    net.optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch:', epoch, 'Loss:', net.loss.item())\n",
    "    \n",
    "y_pred = net(test_images)\n",
    "_, predicted = torch.max(y_pred, 1)\n",
    "\n",
    "print(accuracy_score(test_labels, predicted))\n",
    "print(confusion_matrix(test_labels, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
